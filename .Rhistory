library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
hist(construction$Bid_Price__Millions_) # Replace variable as needed to generate histograms
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(readxl)
df_monthly_index <- read_excel("Desktop/df_monthly_index.csv")
View(df_monthly_index)
df_monthly_index <- read.csv("~/Desktop/df_monthly_index.csv")
View(df_monthly_index)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=132)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=144)
View(season)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=1548)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T)
View(season)
#################################
#                               #
#       MSA Class of 2019       #
#                               #
#      Logistic Regression      #
#        Final Project          #
#        Orange Team 2          #
#                               #
#################################
#install.packages(c('expsmooth','lmtest','zoo','seasonal','haven','fma','gmodels','car','tseries','descr','forecast','brglm2','moments'))
library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
sum(construction$Won)
87/543
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
View(construction_train)
hist(construction$competitor_C) # Replace variable as needed to generate histograms
View(construction_valid)
View(construction)
hist(as.numeric(construction$competitor_C)) # Replace variable as needed to generate histograms
hist(as.numeric(construction$Competitor_C)) # Replace variable as needed to generate histograms
hist(construction$Competitor_C) # Replace variable as needed to generate histograms
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(ggplot2)
file.dir <- "/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Time Series/Data/"
input.file1 <- "usa_tx_noaa.sas7bdat"
input.file2 <- "airline.sas7bdat"
#### Sine and Cosine in ARIMA
tx <- read_sas(paste(file.dir, input.file1, sep = ""))
airline <- read_sas(paste(file.dir, input.file2, sep = ""))
tx.ts<-ts(tx$Temperature,frequency = 12)
air.ts<-ts(airline$LogPsngr,frequency = 12)
index.ts=seq(1,length(tx.ts))
x1.sin=sin(2*pi*index.ts*1/12)
x1.cos=cos(2*pi*index.ts*1/12)
x2.sin=sin(2*pi*index.ts*2/12)
x2.cos=cos(2*pi*index.ts*2/12)
x3.sin=sin(2*pi*index.ts*3/12)
x3.cos=cos(2*pi*index.ts*3/12)
x4.sin=sin(2*pi*index.ts*4/12)
x4.cos=cos(2*pi*index.ts*4/12)
x.reg=cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos)
arima.1<-Arima(tx.ts,order=c(0,0,0),xreg=x.reg)
summary(arima.1)
arima.2<-Arima(tx.ts,order=c(0,0,0),xreg=fourier(tx.ts,K=4))
summary(arima.2)
###Creating an STL with multiple seasons
#Number of calls handled on weekdays between 7:00 am and 9:05 pm
# Five-minute call volume from March 3, 2003, to May 23, 2003
# in a large North American commercial bank.
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
summary(arima.1)
summary(arima.2)
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
install.packages("esquisse")
library(esquisse)
esquisse()
esquisse:::esquisser()
library(plyr)
esquisser()
library(plyr)
library(tidyverse)
library(xlsx)
library(zoo)
library(forecast)
library(imputeTS)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(seasonal)
library(tseries)
library(ggplot2)
library(data.table)
library(reshape2)
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
head(well)
rain <- rain[69222:,]
rain <- rain[69222:nrow(rain),]
tide <- tide[173032:nrow(tide),]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
View(well)
View(rain)
rain$date_hour <- paste(rain$date,paste(substr(rain$time,1,2)),":00",sep=""),sep=" ")
rain$date_hour <- paste(rain$date,paste(substr(rain$time,1,2),":00",sep=""),sep=" ")
rain$date_hour <- paste(rain$date,paste(substr(rain$Time,1,2),":00",sep=""),sep=" ")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,2),":00",sep=""),sep=" ")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,1),":00",sep=""),sep=" ")
View(tide)
tide$date_hour <- paste(tide$Date,paste(substr(tide$Hour,1,1),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(substr(tide$Time,1,1),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(substr(tide$Time,1,2),":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(rain_agg)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
View(well_agg)
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
View(tide_agg)
View(rain_agg)
View(tide_agg)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(tide_agg)
View(tide_agg)
View(tide)
if (substr(tide$Time,1,1) == 0) {
tide$Time = substr(tide$Time,2,1)
}
if (substr(tide$Time,1,1) == '0') {
tide$Time = substr(tide$Time,2,1)
}
if (substr(tide$Time,1,1) = '0') {
tide$Time = substr(tide$Time,2,1)
}
ifelse(substr(tide$Time,1,1) == '0',tide$Time = substr(tide$Time,2,1),tide$Time = tide$Time)
ifelse(substr(tide$Time,1,1) = '0',tide$Time = substr(tide$Time,2,1),tide$Time = tide$Time)
tide$new_hour <- ifelse(substr(tide$Time,1,1) = '0',substr(tide$Time,2,1),tide$Time)
tide$new_hour <- ifelse(substr(tide$Time,1,1) == '0',substr(tide$Time,2,1),tide$Time)
tide <- read.csv("station_8722802.csv")
tide <- tide[173032:nrow(tide),]
tide$new_hour <- ifelse(substr(tide$Time,1,1) == '0',substr(tide$Time,2,1),tide$Time)
tide$new_hour <- ifelse(as.numeric(substr(tide$Time,1,1)) == 0,substr(tide$Time,2,1),tide$Time)
tide$hour_check <- as.numeri(substr(tide$Time,1,2))
tide$hour_check <- as.numeric(substr(tide$Time,1,2))
tide$hour_check <- substr(tide$Time,1,2)
View(tide)
class(tide$hour_check)
tide$hour_check <- substr(tide$Time,1,1)
class(tide$hour_check)
tide$new_hour <- ifelse(tide$hour_check == '0',substr(tide$Time,2,1),tide$Time)
tide$new_hour <- ifelse(tide$hour_check == '0',0,1)
tide$hour2 <- substr(tide$Time,1,2)
tide$hour1 <- substr(tide$Time,2,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(tide_agg)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
View(tide_agg)
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(tide_agg)
View(well_agg)
head(tide_agg)
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
View(tide_agg)
View(well_agg)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
View(well_agg)
well_agg <- well_agg[order(well_agg$Group.1),]
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
View(tide_agg)
View(well_agg)
View(rain_agg)
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
View(well_agg)
View(tide_agg)
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(rain_agg)
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
tail(tide_agg)
tail(rain_agg)
View(rain)
View(tide)
well <- well[1:112063,] # Remove values having code P
rain <- rain[69222:443908,]
tide <- tide[173032:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,1),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(tide_agg)
View(rain_agg)
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69222:443908,]
tide <- tide[173032:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,1),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(rain_agg)
View(rain)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69222:443908,]
tide <- tide[173032:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), mean)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
nrow(full_date_time) - nrow(well_agg) # 497 entries missing
colnames(full_date_time) <- c("Date_Time")
View(rain_agg)
well <- well[1:112063,] # Remove values having code P
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(rain_agg)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
nrow(full_date_time) - nrow(well_agg) # 497 entries missing
colnames(full_date_time) <- c("Date_Time")
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
View(tide_imputed)
sum(is.na(tide_imputed$Tide_Height))
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
sum(is.na(tide_imputed$Tide_Height)) # No more NA values
