library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Sector + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
cor(construction_train)
View(construction_train)
for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16)) {
if (skewness(construction[,i]) > 2) {
print(skewness(construction[,i]))
}
} # Competitors, C, D, and G all have high values here
for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16)) {
if (kurtosis(construction[,i]) > 5) {
print(kurtosis(construction[,i]))
}
} # Five variables of interest - Competitors C, D, and G, Cost After Eng. Estimate, and Bid Win Diff
##possible outliers...need to recheck in the model
boxplot(construction_train$Estimated_Years_to_Complete)
construction_train$Estimated_Years_to_Complete2[construction_train$Estimated_Years_to_Complete>15]
hist(construction$Competitor_A) # Replace variable as needed to generate histograms
vif(construction_ref) # No more multicollinearity present
construction$test1 <- ifelse(construction$Sector == "1",1,0)
construction$test2 <- ifelse(construction$Sector == "2",1,0)
construction$test3 <- ifelse(construction$Sector == "3",1,0)
construction$test4 <- ifelse(construction$Sector == "4",1,0)
construction$test5 <- ifelse(construction$Sector == "5",1,0)
construction$test6 <- ifelse(construction$Sector == "6",1,0)
construction$test7 <- ifelse(construction$Sector == "7",1,0)
construction$test8 <- ifelse(construction$Sector == "8",1,0)
construction$test9 <- ifelse(construction$Sector == "9",1,0)
construction$test10 <- ifelse(construction$Sector == "10",1,0)
View(construction)
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G,Sector))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_ + test1+ test2+ test3+ test4+ test5+ test6+ test7+ test8+ test9+ test10, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16)) {
if (skewness(construction[,i]) > 2) {
print(skewness(construction[,i]))
}
} # Competitors, C, D, and G all have high values here
for (i in c(1,2,3,6,7,8,9,10,11,12,13,14,15,16)) {
if (kurtosis(construction[,i]) > 5) {
print(kurtosis(construction[,i]))
}
} # Five variables of interest - Competitors C, D, and G, Cost After Eng. Estimate, and Bid Win Diff
library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
hist(construction$Bid_Price__Millions_) # Replace variable as needed to generate histograms
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(readxl)
df_monthly_index <- read_excel("Desktop/df_monthly_index.csv")
View(df_monthly_index)
df_monthly_index <- read.csv("~/Desktop/df_monthly_index.csv")
View(df_monthly_index)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=132)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=144)
View(season)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=1548)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T)
View(season)
#################################
#                               #
#       MSA Class of 2019       #
#                               #
#      Logistic Regression      #
#        Final Project          #
#        Orange Team 2          #
#                               #
#################################
#install.packages(c('expsmooth','lmtest','zoo','seasonal','haven','fma','gmodels','car','tseries','descr','forecast','brglm2','moments'))
library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
sum(construction$Won)
87/543
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
View(construction_train)
hist(construction$competitor_C) # Replace variable as needed to generate histograms
View(construction_valid)
View(construction)
hist(as.numeric(construction$competitor_C)) # Replace variable as needed to generate histograms
hist(as.numeric(construction$Competitor_C)) # Replace variable as needed to generate histograms
hist(construction$Competitor_C) # Replace variable as needed to generate histograms
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(ggplot2)
file.dir <- "/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Time Series/Data/"
input.file1 <- "usa_tx_noaa.sas7bdat"
input.file2 <- "airline.sas7bdat"
#### Sine and Cosine in ARIMA
tx <- read_sas(paste(file.dir, input.file1, sep = ""))
airline <- read_sas(paste(file.dir, input.file2, sep = ""))
tx.ts<-ts(tx$Temperature,frequency = 12)
air.ts<-ts(airline$LogPsngr,frequency = 12)
index.ts=seq(1,length(tx.ts))
x1.sin=sin(2*pi*index.ts*1/12)
x1.cos=cos(2*pi*index.ts*1/12)
x2.sin=sin(2*pi*index.ts*2/12)
x2.cos=cos(2*pi*index.ts*2/12)
x3.sin=sin(2*pi*index.ts*3/12)
x3.cos=cos(2*pi*index.ts*3/12)
x4.sin=sin(2*pi*index.ts*4/12)
x4.cos=cos(2*pi*index.ts*4/12)
x.reg=cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos)
arima.1<-Arima(tx.ts,order=c(0,0,0),xreg=x.reg)
summary(arima.1)
arima.2<-Arima(tx.ts,order=c(0,0,0),xreg=fourier(tx.ts,K=4))
summary(arima.2)
###Creating an STL with multiple seasons
#Number of calls handled on weekdays between 7:00 am and 9:05 pm
# Five-minute call volume from March 3, 2003, to May 23, 2003
# in a large North American commercial bank.
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
summary(arima.1)
summary(arima.2)
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
well <- well[1:112063,] # Remove values having code P
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$Time <- as.character(rain$Time)
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
nrow(full_date_time) - nrow(well_agg) # 497 entries missing
colnames(full_date_time) <- c("Date_Time")
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
# Packages
library(plyr)
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
library(zoo)
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # No more NA values
sum(is.na(tide_imputed$Tide_Height)) # No more NA values
rain_imputed <- rain_agg
write.csv(well_imputed, "well_1260_rain_imputed.csv")
write.csv(tide_imputed, "well_1260_tide_imputed.csv")
write.csv(rain_imputed, "well_1260_rain_imputed.csv")
# Join together into one set and write out all sets
merged_set <- join(well_imputed,tide_imputed,by="Date_Time",type="left")
View(merged_set)
merged_set <- join(merged_set,rain_imputed,by="Date_Time",type="left")
View(merged_set)
write.csv(merged_set, "G-1260_merged_data.csv")
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69237:443908,]
tide <- tide[173071:1109640,]
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
View(rain)
View(tide)
View(well)
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(rain_agg)
View(tide_agg)
View(well_agg)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
View(well_agg)
View(tide_agg)
View(rain_agg)
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(well_agg)
View(tide_agg)
View(rain_agg)
nrow(full_date_time) - nrow(rain_agg)
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
nrow(full_date_time) - nrow(well_agg) # 497 entries missing
nrow(full_date_time) - nrow(rain_agg)
nrow(full_date_time) - nrow(rain_agg)
nrow(full_date_time) - nrow(tide_agg)
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- rain_agg
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- rain_agg
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # No more NA values
sum(is.na(tide_imputed$Tide_Height)) # No more NA values
# Join together into one set and write out all sets
merged_set <- join(well_imputed,tide_imputed,by="Date_Time",type="left")
merged_set <- join(merged_set,rain_imputed,by="Date_Time",type="left")
write.csv(merged_set, "G-1260_merged_data.csv")
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well_data <- read.csv("G-1260_merged_data.csv")
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well_data <- read.csv("G-1260_merged_data.csv")
well.ts <- ts(well_data$Avg_Corrected_Well_Height,frequency = 8766)
index.ts =seq(1,length(well.ts))
x1.sin=sin(2*pi*index.ts*1/8766)
x1.cos=cos(2*pi*index.ts*1/8766)
x2.sin=sin(2*pi*index.ts*2/8766)
x2.cos=cos(2*pi*index.ts*2/8766)
x3.sin=sin(2*pi*index.ts*3/8766)
x3.cos=cos(2*pi*index.ts*3/8766)
x4.sin=sin(2*pi*index.ts*4/8766)
x4.cos=cos(2*pi*index.ts*4/8766)
x.reg=cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos)
library(forecast)
arima.1 <- auto.arima(well.ts, d=1, max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg, parallel=TRUE)
arima.1 <- auto.arima(well.ts, d=1, max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg)
arima.1 <- auto.arima(well.ts, max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg)
arima.1 <- auto.arima(well.ts, d=1,max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
Acf(arima.1, lag = 10)$acf
Acf(well.ts, lag = 10)$acf
Pacf(well.ts, lag = 10)$acf
Acf(arima.1$residuals, lag = 10)$acf
Pacf(arima.1$residuals, lag = 10)$acf
Acf(arima.1$residuals, lag = 10)$acf
Pacf(arima.1$residuals, lag = 10)$acf
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 2)$p.value
}
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(dyn)
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 2)$p.value
}
White.LB <- pmin(White.LB, 0.2)
barplot(White.LB, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 1)$p.value
}
White.LB <- pmin(White.LB, 0.2)
barplot(White.LB, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
arima.1 <- auto.arima(well.ts, d=1,max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE, parallel=TRUE)
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos,well_data$Tide_Height,well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=3, max.q=3, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=6, max.q=6, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
Acf(arima.1$residuals, lag = 10)$acf
Pacf(arima.1$residuals, lag = 10)$acf
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 1)$p.value
}
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
Acf(arima.1$residuals, lag = 24)$acf
Pacf(arima.1$residuals, lag = 24)$acf
Pacf(arima.1$residuals, lag = 24)$pacf
Acf(arima.1$residuals, lag = 24)$pacf
x3.sin <- sin(2*pi*index.ts*3/8766)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=24, max.q=24, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE, stepwise=FALSE, parallel=TRUE)
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos,well_data$Tide_Height,well_data$Rain_Amt)
View(x.reg)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE, stepwise=FALSE, parallel=TRUE)
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well_data <- read.csv("G-1260_merged_data.csv")
well.ts <- ts(well_data$Avg_Corrected_Well_Height,frequency  <-  8766)
index.ts <- seq(1,length(well.ts))
x1.sin <- sin(2*pi*index.ts*1/8766)
x1.cos <- cos(2*pi*index.ts*1/8766)
x2.sin <- sin(2*pi*index.ts*2/8766)
x2.cos <- cos(2*pi*index.ts*2/8766)
x3.sin <- sin(2*pi*index.ts*3/8766)
x3.cos <- cos(2*pi*index.ts*3/8766)
x4.sin <- sin(2*pi*index.ts*4/8766)
x4.cos <- cos(2*pi*index.ts*4/8766)
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos,well_data$Tide_Height,well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE, stepwise=FALSE, parallel=TRUE)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
Acf(arima.1$residuals, lag = 24)$acf
Pacf(arima.1$residuals, lag = 24)$acf
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 1)$p.value
}
White.LB <- pmin(White.LB, 0.2)
barplot(White.LB, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos,well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos,well_data$Tide_Height)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
x.reg <- cbind(x1.sin,x1.cos,x2.sin,x2.cos,well_data$Tide_Height,well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
x.reg <- cbind(well_data$Tide_Height,well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
arima.1 <- auto.arima(well.ts, d=0, D=0, max.p=12, max.q=12, max.P=0, max.Q=0, xreg <- x.reg, seasonal=FALSE)
summary(arima.1)
Acf(arima.1$residuals, lag = 24)$acf
Pacf(arima.1$residuals, lag = 24)$acf
arima.1 <- auto.arima(well.ts, xreg <- x.reg,)
arima.1 <- auto.arima(well.ts, xreg <- x.reg)
arima.1 <- auto.arima(well.ts, d=1, xreg <- x.reg)
summary(arima.1)
arima.1 <- auto.arima(well.ts, d=1, D=1, xreg <- x.reg)
summary(arima.1)
Acf(arima.1$residuals, lag = 24)$acf
Pacf(arima.1$residuals, lag = 24)$acf
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(arima.1$residuals, lag = i, type = "Ljung", fitdf = 1)$p.value
}
White.LB <- pmin(White.LB, 0.2)
barplot(White.LB, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
x.reg <- cbind(x1.sin, x1.cos, x2.sin, x2.cos, x3.sin, x3.cos, x4.sin, x4.cos, well_data$Tide_Height, well_data$Rain_Amt)
arima.1 <- auto.arima(well.ts, d=1, D=1, xreg <- x.reg)
summary(arima.1)
