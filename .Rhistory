library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
hist(construction$Bid_Price__Millions_) # Replace variable as needed to generate histograms
library(forecast)
library(haven)
library(fma)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(readxl)
df_monthly_index <- read_excel("Desktop/df_monthly_index.csv")
View(df_monthly_index)
df_monthly_index <- read.csv("~/Desktop/df_monthly_index.csv")
View(df_monthly_index)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=129)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=132)
season=matrix(rep(c(1,0,0,0,0,0,0,0,0,0,0,0),12),byrow=T,nrow=144)
View(season)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T,nrow=1548)
season=matrix(rep(c(0,0,0,0,0,0,0,0,0,1,0,0),12),byrow=T)
View(season)
#################################
#                               #
#       MSA Class of 2019       #
#                               #
#      Logistic Regression      #
#        Final Project          #
#        Orange Team 2          #
#                               #
#################################
#install.packages(c('expsmooth','lmtest','zoo','seasonal','haven','fma','gmodels','car','tseries','descr','forecast','brglm2','moments'))
library(car)
library(gmodels)
library(forecast)
library(haven)
library(fma)
library(descr)
library(expsmooth)
library(lmtest)
library(zoo)
library(seasonal)
library(brglm)
library(brglm2)
library(moments)
library(caret)
options(scipen=999) # Improve readability of parameter estimates
set.seed(1452) # Set seed to replicate results
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
sum(construction$Won)
87/543
file.dir <- '/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Logistic Regression/Final Project/' # Replace with path to your file
input.file1 <- "construction.sas7bdat"
construction <- read_sas(paste(file.dir, input.file1,sep = "")) # Read in training set
construction$Bid_Win_Difference <- round(construction$Bid_Price__Millions_ - construction$Winning_Bid_Price__Millions_,2) # Creating this variable is one way to resolve all multicollinearity
construction$Won <- ifelse(construction$Win_Bid == "Yes",1,0)
construction$Sector <- as.factor(construction$Sector) # Change Sector to categorical variable
construction <- subset(construction, select = -c(Win_Bid,Competitor_C,Competitor_D,Competitor_G))
summary(construction) # Summarize to check for missing values and descriptive statistics
inTrain <- createDataPartition(y=construction$Won, p=0.70, list=FALSE) # Creating partitions randomly
construction_train <- construction[inTrain,]
construction_valid <- construction[-inTrain,]
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
control1 <- glm.control1(maxit = 100) # Need to increase the maximum number of model iterations so that brglm can run successfully
construction_ref <- brglm(Won ~ Estimated_Cost__Millions_ + Estimated_Years_to_Complete + Region_of_Country + Number_of_Competitor_Bids + Competitor_A + Competitor_B + Competitor_E + Competitor_F + Competitor_H + Competitor_I + Competitor_J + Bid_Win_Difference + Cost_After_Engineering_Estimate_, data = construction_train, family = binomial(link = "logit"), control.glm = control1) # This new model with Bid_Win_Difference eliminates all multicollinearity present in the model
summary(construction_ref)
vif(construction_ref) # No more multicollinearity present
View(construction_train)
hist(construction$competitor_C) # Replace variable as needed to generate histograms
View(construction_valid)
View(construction)
hist(as.numeric(construction$competitor_C)) # Replace variable as needed to generate histograms
hist(as.numeric(construction$Competitor_C)) # Replace variable as needed to generate histograms
hist(construction$Competitor_C) # Replace variable as needed to generate histograms
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(ggplot2)
file.dir <- "/Users/matttrombley/Dropbox/Fall 2018/Fall 1/Time Series/Data/"
input.file1 <- "usa_tx_noaa.sas7bdat"
input.file2 <- "airline.sas7bdat"
#### Sine and Cosine in ARIMA
tx <- read_sas(paste(file.dir, input.file1, sep = ""))
airline <- read_sas(paste(file.dir, input.file2, sep = ""))
tx.ts<-ts(tx$Temperature,frequency = 12)
air.ts<-ts(airline$LogPsngr,frequency = 12)
index.ts=seq(1,length(tx.ts))
x1.sin=sin(2*pi*index.ts*1/12)
x1.cos=cos(2*pi*index.ts*1/12)
x2.sin=sin(2*pi*index.ts*2/12)
x2.cos=cos(2*pi*index.ts*2/12)
x3.sin=sin(2*pi*index.ts*3/12)
x3.cos=cos(2*pi*index.ts*3/12)
x4.sin=sin(2*pi*index.ts*4/12)
x4.cos=cos(2*pi*index.ts*4/12)
x.reg=cbind(x1.sin,x1.cos,x2.sin,x2.cos,x3.sin,x3.cos,x4.sin,x4.cos)
arima.1<-Arima(tx.ts,order=c(0,0,0),xreg=x.reg)
summary(arima.1)
arima.2<-Arima(tx.ts,order=c(0,0,0),xreg=fourier(tx.ts,K=4))
summary(arima.2)
###Creating an STL with multiple seasons
#Number of calls handled on weekdays between 7:00 am and 9:05 pm
# Five-minute call volume from March 3, 2003, to May 23, 2003
# in a large North American commercial bank.
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
summary(arima.1)
summary(arima.2)
calls <- unlist(read.csv("https://robjhyndman.com/data/callcenter.txt",
header=TRUE,sep="\t")[,-1])
calls <- msts(calls, start=1, seasonal.periods = c(169, 169*5))
calls %>% mstl() %>%
autoplot() + xlab("Week")
fit <- auto.arima(calls, seasonal=FALSE,
xreg=fourier(calls, K=c(10,10)))
tide <- read.csv("station_8722802.csv")
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
tide1 <- tide[0:500000,]
tide2 <- tide[500001:nrow(tide),]
library(data.table)
fwrite(tide1, "tide1.csv")
fwrite(tide2, "tide2.csv")
tide <- tide[173071:1109640,]
fwrite(tide, "tides.csv")
tide <- tide[173067:1109636,]
tide <- read.csv("station_8722802.csv")
tide <- tide[173067:1109636,]
fwrite(tide, "tides.csv")
tide <- read.csv("station_8722802.csv")
View(tide)
View(tide)
View(well)
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69237:443908,]
tide <- tide[173031:1109630,]
fwrite(tide, "tides.csv")
View(well)
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
View(well)
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$Combined_DateTime), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
View(well_agg)
well$date_hour <- paste(paste(well$Date,substr(well$time,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$Combined_DateTime), mean)
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69237:443908,]
tide <- tide[173031:1109630,]
# Create a time element that is hourly to aggregate on
well$time <- as.character(well$time)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$Date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
well$date_hour <- paste(paste(well$date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(well_agg)
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 01:00:00',tz='EST')
x2 <- as.POSIXct('2018-06-07 23:00:00',tz='EST')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
View(full_date_time)
nrow(full_date_time) - nrow(well_agg) # 494 row difference
nrow(full_date_time) - nrow(rain_agg) # 0 row difference
nrow(full_date_time) - nrow(tide_agg) # 11 row difference
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
# Packages
library(plyr)
library(zoo)
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- join(full_date_time,rain_agg, by = "Date_Time", type = "left")
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
sum(is.na(rain_imputed$Rain_Amt)) # 16
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # No more NA values
rain_imputed$Rain_Amt <- na.approx(rain_imputed$Rain_Amt)
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69237:443908,]
tide <- tide[173031:1109630,]
# Create a time element that is hourly to aggregate on
well$time <- as.character(well$time)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 01:00:00',tz='EST')
x2 <- as.POSIXct('2018-06-07 23:00:00',tz='EST')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
nrow(full_date_time) - nrow(well_agg) # 508 row difference
nrow(full_date_time) - nrow(rain_agg) # 3 row difference
nrow(full_date_time) - nrow(tide_agg) # 11 row difference
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- join(full_date_time,rain_agg, by = "Date_Time", type = "left")
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 513 NA values - can impute
sum(is.na(tide_imputed$Tide_Height)) # 16
sum(is.na(rain_imputed$Rain_Amt)) # 4
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
which(is.na(tide_imputed$Tide_Height)) # Index of missing values
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
View(rain)
rain[69327,
]
rain[69237,]
rain[69220:69237,]
rain[443908,]
rain[443880:443908,]
# Packages
library(plyr)
library(zoo)
# Working directories and file paths
setwd("/Users/matttrombley/Documents/GitHub/Time-Series-2-/")
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69221:443888,]
# Create a time element that is hourly to aggregate on
well$time <- as.character(well$time)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
# Create a time element that is hourly to aggregate on
well$UTC_Hour <- as.character(well$UTC_Hour)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$UTC_Date,substr(well$UTC_Hour,1,nchar(well$UTC_Hour)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 05:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
nrow(full_date_time) - nrow(well_agg)
nrow(full_date_time) - nrow(rain_agg)
nrow(full_date_time) - nrow(tide_agg)
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
View(well_imputed)
View(tide_imputed)
View(rain_agg)
rain_imputed <- join(full_date_time,rain_agg, by = "Date_Time", type = "left")
sum(is.na(rain_agg$Rain_Amt))
sum(is.na(rain_imputed$Rain_Amt))
rain_imputed$Rain_Amt <- na.approx(rain_imputed$Rain_Amt)
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
View(tide)
View(well)
View(well)
View(tide)
View(rain)
View(tide)
tide[1109630,]
well[112063,]
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$datebstr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
well$date_hour <- paste(paste(well$date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
# Create a time element that is hourly to aggregate on
well$time <- as.character(well$time)
well$date_hour <- paste(paste(well$date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
well <- read.csv("G-1260_T.csv")
rain <- read.csv("G-1260_T_rain.csv")
tide <- read.csv("station_8722802.csv")
# Remove values having code P and make time indices match well data
well <- well[1:112063,]
rain <- rain[69221:443908,]
tide <- tide[173031:1109630,]
# Create a time element that is hourly to aggregate on
well$time <- as.character(well$time)
rain$Time <- as.character(rain$Time)
tide$hour_check <- substr(tide$Time,1,1)
tide$hour1 <- substr(tide$Time,2,2)
tide$hour2 <- substr(tide$Time,1,2)
tide$new_hour <- ifelse(tide$hour_check == '0',tide$hour1,tide$hour2)
well$date_hour <- paste(paste(well$date,substr(well$time,1,nchar(well$time)-3),sep=" "),":00",sep="")
rain$date_hour <- paste(rain$Date,paste(substr(rain$Time,1,nchar(rain$Time)-3),":00",sep=""),sep=" ")
tide$date_hour <- paste(tide$Date,paste(tide$new_hour,":00",sep=""),sep=" ")
# Aggregate the corrected well height data to hourly
well_agg <- aggregate(well$Corrected, list(well$date_hour), mean)
rain_agg <- aggregate(rain$RAIN_FT, list(rain$date_hour), sum)
tide_agg <- aggregate(tide$Prediction, list(tide$date_hour), mean)
# Clean up formatting of dates, times, and row/column names
well_agg$Group.1 <- as.POSIXct(strptime(well_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
rain_agg$Group.1 <- as.POSIXct(strptime(rain_agg$Group.1, "%m/%d/%y %H:%M"), tz="UTC")
tide_agg$Group.1 <- as.POSIXct(strptime(tide_agg$Group.1, "%Y-%m-%d %H:%M"), tz="UTC")
View(tide_agg)
View(well_agg)
well_agg <- well_agg[order(well_agg$Group.1),]
rain_agg <- rain_agg[order(rain_agg$Group.1),]
tide_agg <- tide_agg[order(tide_agg$Group.1),]
rownames(well_agg) <- 1:nrow(well_agg)
rownames(rain_agg) <- 1:nrow(rain_agg)
rownames(tide_agg) <- 1:nrow(tide_agg)
colnames(well_agg) <- c("Date_Time", "Avg_Corrected_Well_Height")
colnames(rain_agg) <- c("Date_Time", "Rain_Amt")
colnames(tide_agg) <- c("Date_Time", "Tide_Height")
View(rain_agg)
# Check to see if there are missing values
x1 <- as.POSIXct('2007-10-01 01:00:00',tz='UTC')
x2 <- as.POSIXct('2018-06-08 00:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
nrow(full_date_time) - nrow(well_agg) # 494 row difference
nrow(full_date_time) - nrow(rain_agg) # 0 row difference
nrow(full_date_time) - nrow(tide_agg) # 11 row difference
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- rain_agg
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 497 NA values - can impute
sum(is.na(tide_imputed$Tide_Height))
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
x2 <- as.POSIXct('2018-06-07 23:00:00',tz='UTC')
full_date_time <- as.data.frame(seq(from=x1,to=x2,by="hour"))
colnames(full_date_time) <- c("Date_Time")
nrow(full_date_time) - nrow(well_agg) # 509 row difference
nrow(full_date_time) - nrow(rain_agg) # 0 row difference
nrow(full_date_time) - nrow(tide_agg) # 12 row difference
# Create full data set including missing times
well_imputed <- join(full_date_time,well_agg, by = "Date_Time", type = "left")
tide_imputed <- join(full_date_time,tide_agg, by = "Date_Time", type = "left")
rain_imputed <- rain_agg
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # 509 NA values - can impute
sum(is.na(tide_imputed$Tide_Height)) #12 NA values - can impute
# Impute missing values with desired measure
well_imputed$Avg_Corrected_Well_Height <- na.approx(well_imputed$Avg_Corrected_Well_Height)
tide_imputed$Tide_Height <- na.approx(tide_imputed$Tide_Height)
sum(is.na(well_imputed$Avg_Corrected_Well_Height)) # No more NA values
sum(is.na(tide_imputed$Tide_Height)) # No more NA values
View(rain_agg)
rain_imputed <- rain_agg[1:(nrow(rain_agg)-1),]
# Join together into one set and write out all sets
merged_set <- join(well_imputed,tide_imputed,by="Date_Time",type="left")
merged_set <- join(merged_set,rain_imputed,by="Date_Time",type="left")
write.csv(merged_set, "G-1260_merged_data.csv")
